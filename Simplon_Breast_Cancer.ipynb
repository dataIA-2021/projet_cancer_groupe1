{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49866e07",
   "metadata": {},
   "source": [
    "# Introduction à la classification binaire\n",
    "# Application au diagnostic du cancer du sein\n",
    "\n",
    "Travail en groupe 3/4, sur la semaine 50\n",
    "\n",
    "## Projet Breast Cancer Wisconsin\n",
    "Les données: \n",
    "https://www.kaggle.com/uciml/breast-cancer-wisconsin-data\n",
    "\n",
    "Nous allons étudier le concept de classification qui est avec la régression l'autre tâche principale du Machine Learning supervisé. Nous allons particulièrement nous concentrer sur la classification binaire et l'illustrer sur un exemple d'application concret, le diagnostic du cancer du sein. En outre, nous allons découvrir et utiliser la régression logistique comme modèle de Machine Learning pour effectuer notre tâche de classification binaire.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248d6101",
   "metadata": {},
   "source": [
    "## Contexte\n",
    "Le Breast Cancer Wisconsin (diagnostic) Dataset est un jeu de données classique du Machine Learning. Il est composé de 569 exemples, chaque exemple étant défini par 30 caractéristiques ; ces caractéristiques correspondent principalement aux propriétés géométriques mesurées sur les cellules issues de la biopsie. Chaque exemple est classé dans la catégorie \"Benign\" (n=357) si la tumeur est bénigne et dans la catégorie \"Malignant\" (n=212) si la tumeur est maline. Le nombre de catégories de la classification est de 2, on parle alors de classification binaire. La finalité de ce travail est ainsi d'entrainer un modèle de Machine Learning à identifier le type de tumeur (bénigne ou maline) en fonction des propriétés géométriques mesurées sur les cellules issues de la biopsie.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadd6423",
   "metadata": {},
   "source": [
    "### concepts de base de la classification binaire :\n",
    "Lister:\n",
    "\n",
    "    En quoi consiste la classification binaire ?\n",
    "    Qu'est-ce qu'une matrice de confusion ?\n",
    "        Qu'est-ce qu'un faux négatif ? un vrai négatif ? un faux positif ? un vrai positif ?\n",
    "    Qu'est-ce que le taux de classification (accuracy) ?\n",
    "    Qu'est-ce que le rappel (recall) ?\n",
    "    Qu'est-ce que la précision (precision) ?\n",
    "    Qu'est-ce que le F1-score ?\n",
    "    Qu'est-ce qu'une courbe ROC ?\n",
    "        Qu'est-ce que l'Area Under the Curve (AUC) ?\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3acb6e77",
   "metadata": {},
   "source": [
    "La classification binaire consiste à entrainer le modèle de machine learning à identifier 2 catégories en fonction des données quantitatives que nous avons dans notre dataset.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "edcb1dbc",
   "metadata": {},
   "source": [
    "Une matrice de confusion est un outil permettant de mesurer les performances d’un modèle de Machine Learning en vérifiant notamment à quelle fréquence ses prédictions sont exactes par rapport à la réalité dans des problèmes de classification."
   ]
  },
  {
   "cell_type": "raw",
   "id": "4bbe8fba",
   "metadata": {},
   "source": [
    "Ces résultats peuvent être l’indication correcte d’une prédiction positive comme  » vraie positive  » (true positive) et d’une prédiction négative comme  » vraie négative  » (true negative), ou une prédiction positive incorrecte comme  » fausse positive  » (false positive) et une prédiction négative incorrecte comme  » fausse négative  » (false negative)."
   ]
  },
  {
   "cell_type": "raw",
   "id": "36955ef7",
   "metadata": {},
   "source": [
    "L’indicateur le plus simple est l’accuracy : il indique le pourcentage de bonnes prédictions. C’est un très bon indicateur parce qu’il est très simple à comprendre."
   ]
  },
  {
   "cell_type": "raw",
   "id": "380f3579",
   "metadata": {},
   "source": [
    "Pour compléter l’accuracy, on calcule également le recall : il se concentre uniquement sur les id  qui ont réellement le cancer et donne une indication sur la part de faux négatifs. Les faux négatifs ce sont les id qui ont le cancer mais qui ne sont pas détectés par le score. Concrètement ce sont des id que vous ne détectez pas et pour lesquels vous ne pourrez pas agir pour éviter leur départ."
   ]
  },
  {
   "cell_type": "raw",
   "id": "d2ea4dc2",
   "metadata": {},
   "source": [
    "Enfin, un 3ème indicateur vient compléter l’accuracy et le recall, c’est la precision : il se concentre uniquement sur les id pour lesquels le modèle a prédit un cancer et donne une indication sur les faux positifs. Les faux positifs ce sont les id pour lesquels le score a prédit un cancer mais qui ont une tumeur begnine. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "477e5049",
   "metadata": {},
   "source": [
    "Le F1 Score permet d’effectuer une bonne évaluation de la performance de notre modèle.\n",
    "Le F1-Score combine subtilement la précision et le rappel. Il est intéressant et plus intéressant que l’accuracy car le nombre de vrais négatifs (tn) n’est pas pris en compte. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "822c820d",
   "metadata": {},
   "source": [
    "Courbe ROC est utilisé pour evaluer les performances du modèle.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "46444078",
   "metadata": {},
   "source": [
    "# Area Under the Curve (AUC) , L’AUC correspond à la probabilité pour qu’un événement positif soit classé comme positif par le test sur l’étendue des valeurs seuil possibles. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318b39db",
   "metadata": {},
   "source": [
    "### Etude\n",
    "décrire:\n",
    "\n",
    "    Qu'est-ce qu'une régression logistique ?\n",
    "    Qu'est-ce que le Feature Scaling ?\n",
    "        A quoi sert-il et quels sont ses avantages ?\n",
    "        Qu'est-ce que la normalisation des données ?\n",
    "        Qu'est-ce que la standardisation des données ?\n",
    "        Comment l'utilise-t-on lorsque l'on a un jeu de train et un jeu de test ?\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "84711c4b",
   "metadata": {},
   "source": [
    "Un modèle de régression logistique permet aussi de prédire la probabilité qu’un événement arrive (valeur de 1) ou non (valeur de 0) à partir de l’optimisation des coefficients de régression. Ce résultat varie toujours entre 0 et 1. Lorsque la valeur prédite est supérieure à un seuil, l’événement est susceptible de se produire, alors que lorsque cette valeur est inférieure au même seuil, il ne l’est pas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "17c50b51",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3127128458.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_4619/3127128458.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Le Feature Scaling  est une bonne pratique, pour ne pas dire obligatoire, lors de la modélisation avec du Machine Learning.\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Le Feature Scaling  est une bonne pratique, pour ne pas dire obligatoire, lors de la modélisation avec du Machine Learning.\n",
    "\n",
    "Les algorithmes pour lesquels le feature scaling s’avère nécessaire, sont ceux pour lesquels il faudra\n",
    "\n",
    "    Calculer un vecteur de poids (weights) theta\n",
    "    Calculer des distances pour déduire le degrée de similarité de deux items\n",
    "    Certains algorithmes de Clustering\n",
    "\n",
    "Plus concrétement, voici une liste d’algorithmes non exhaustive pour lesquels il faudra procéder au Feature Scaling :\n",
    "\n",
    "    Logistic Regression\n",
    "    Regression Analysis (polynomial, multivariate regression…)\n",
    "    Support Vector Machines (SVM)\n",
    "    K-Nearest Neighbors (KNN)\n",
    "    K-Means (clustering…)\n",
    "    Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713ed03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "La Normalisation\n",
    "\n",
    "Min-Max Scaling peut- être appliqué quand les données varient dans des échelles différentes. A l’issue de cette transformation, les features seront comprises dans un intervalle fixe [0,1]. Le but d’avoir un tel intervalle restreint est de réduire l’espace de variation des valeurs d’une feature et par conséquent réduire l’effet des outliers.\n",
    "\n",
    "La normalisation peut- être effectuée par la technique du Min-Max Scaling. La transformation se fait grâce à la formule suivante :\n",
    "\n",
    "    \\[X_{normalise} = \\frac{X - X_{min}}{X_{max} - X_{min}}\\]\n",
    "\n",
    "Avec :\n",
    "\n",
    "    X_{min} : la plus petite valeur observée pour la feature X\n",
    "    X_{min} : la plus grande valeur observée pour la feature X\n",
    "    X : La valeur de la feature qu’on cherche à normaliser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88facc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "La Standardisation\n",
    "\n",
    "La standardisation (aussi appelée Z-Score normalisation  à ne pas confondre avec la normalisation du paragraphe précendent) peut- être appliquée quand les input features répondent à des distributions normales (Distributions Gaussiennes) avec des moyennes et des écart-types différents. Par conséquent, cette transformation aura pour impact d’avoir toutes nos features répondant à la même loi normale X \\sim \\mathcal{N} (0, \\, 1).\n",
    "\n",
    "La standardisation peut également être appliquée quand les features ont des unités différentes.\n",
    "\n",
    "La Standardisation est le processus de transformer une feature en une autre qui répondra à la loi normale (Gaussian Distribution) X \\sim \\mathcal{N} (\\mu, \\, \\sigma) avec :\n",
    "\n",
    "    \\mu = 0  La moyenne de la loi de distribution\n",
    "    \\sigma = 1 est l’Écart-type (Standard Deviation)\n",
    "\n",
    "La formule de standardisation d’une feature est la suivante :\n",
    "\n",
    "        \\[z = \\frac{ x - \\mu} {\\sigma} \\]\n",
    "\n",
    "avec :\n",
    "\n",
    "    x la valeur qu’on veut standardiser (input variable)\n",
    "    \\mu la moyenne (mean) des observations pour cette feature\n",
    "    \\sigma est l’ecart-type (Standard Deviation) des observations pour cette feature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125beb23",
   "metadata": {},
   "source": [
    "## Implémentation python\n",
    "Entrainement d'un modèle de type régression logistique à diagnostiquer l'absence ou la présence d'un cancer du sein\n",
    "Les étapes:\n",
    "\n",
    "    Importation des librairies Python\n",
    "    Chargement des données du Breast Cancer Wisconsin (diagnostic) Dataset\n",
    "    Mise au format Numpy des données\n",
    "        Par défaut, patients sains = 0, patients malades = 1.\n",
    "    Echantillonnage des données\n",
    "        NB test_size = 113\n",
    "    Afficher sous forme d'histogrammes la distribution du jeu de données initial, du jeu de train et du jeu de test en fonction de chaque catégorie (bénigne et maline)\n",
    "    Effectuer le Feature Scaling\n",
    "    Entrainer le modèle de régression logistique\n",
    "        model = LogisticRegression(C = 0.1, max_iter = 10000)\n",
    "    Calculer et afficher les performances obtenues sur le jeu d'apprentissage\n",
    "        Matrice de confusion\n",
    "        Taux de classification, Rappel, Précision et F1-Score\n",
    "        Courbe ROC, AUC\n",
    "    Calculer et afficher les performances obtenues sur le jeu de test\n",
    "        Matrice de confusion\n",
    "        Taux de classification, Rappel, Précision et F1-Score\n",
    "        Courbe ROC, AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a4a8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importation librairies Python\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import plotly \n",
    "import plotly.graph_objects as go\n",
    "import chart_studio\n",
    "import chart_studio.plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "plotly.offline.init_notebook_mode()\n",
    "import plotly.express as px\n",
    "from pySankey.sankey import sankey\n",
    "init_notebook_mode(connected=True)         # initiate notebook for offline plot\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "#pio.renderers.default = 'svg'\n",
    "pio.renderers.default = 'browser'\n",
    "import plotly.offline as pyo\n",
    "pyo.init_notebook_mode()\n",
    "from IPython.display import Image, HTML, display, SVG\n",
    "import missingno as msno\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from pywaffle import Waffle\n",
    "import random\n",
    "from pandas_profiling import ProfileReport\n",
    "from notebook.services.config import ConfigManager\n",
    "cm = ConfigManager()\n",
    "cm.update('livereveal', {\n",
    "        'width': 1600,\n",
    "        'height': 900,\n",
    "        'scroll': True,\n",
    "})\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ad4cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chargement jeu de données Breast Cancer\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b878c7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exploration Data Analysis\n",
    "\n",
    "profile = ProfileReport(df, title='Analyse du fichier Breast Cancer', html={'style':{'full_width':True}})\n",
    "profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a65977e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Valeurs manquantes :\n",
    "na_values=msno.matrix(df,figsize=(10,3))\n",
    "na_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bf3bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrait de la colonne avec valeurs manquantes\n",
    "# Drop last column of a dataframe\n",
    "df = df.iloc[: , :-1]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc791002",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Mise au format Numpy des données\n",
    "    #Par défaut, patients sains = 0, patients malades = 1\n",
    "\n",
    "df= df.replace({'M':1,'B':0})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f73886",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d770ea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Echantillonage des données\n",
    "# Load module from scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d0626e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into 2 parts : train & test\n",
    "X=df[['id', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
    "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
    "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
    "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
    "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
    "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
    "       'symmetry_worst', 'fractal_dimension_worst']]\n",
    "y=df[['diagnosis']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.198, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b73f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the size of subset of data\n",
    "print(\"The length of the initial dataset is :\", len(X))\n",
    "print(\"The length of the train dataset is   :\", len(X_train))\n",
    "print(\"The length of the test dataset is    :\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a166b30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/celia/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:478: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:327: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:478: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:327: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:478: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:327: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:478: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:327: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:478: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:327: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:478: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:327: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:478: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:327: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:478: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:327: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:478: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:327: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:478: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:327: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:478: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:327: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:478: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:327: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:478: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:327: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:478: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:327: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:478: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:327: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:478: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:327: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:478: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:327: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:478: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:327: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:478: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:327: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:478: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:327: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:478: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:327: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:478: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:327: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:478: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/scipy/optimize/linesearch.py:327: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "/home/celia/anaconda3/lib/python3.9/site-packages/sklearn/utils/optimize.py:202: ConvergenceWarning:\n",
      "\n",
      "newton-cg failed to converge. Increase the number of iterations.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(penalty='none', solver='newton-cg')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "modele_logit = LogisticRegression(penalty='none',solver='newton-cg')\n",
    "modele_logit.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eef0e59b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>constante</th>\n",
       "      <td>-2.373277e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>3.063399e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius_mean</th>\n",
       "      <td>-1.651326e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_mean</th>\n",
       "      <td>-3.903975e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_mean</th>\n",
       "      <td>-8.076346e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_mean</th>\n",
       "      <td>-1.538918e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_mean</th>\n",
       "      <td>-6.912733e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_mean</th>\n",
       "      <td>5.062547e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_mean</th>\n",
       "      <td>8.992989e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points_mean</th>\n",
       "      <td>3.583258e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_mean</th>\n",
       "      <td>-1.470822e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <td>-8.579488e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius_se</th>\n",
       "      <td>-1.440265e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_se</th>\n",
       "      <td>-4.259302e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_se</th>\n",
       "      <td>1.833983e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_se</th>\n",
       "      <td>2.905569e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_se</th>\n",
       "      <td>1.714537e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_se</th>\n",
       "      <td>1.418742e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_se</th>\n",
       "      <td>1.896924e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points_se</th>\n",
       "      <td>4.237894e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_se</th>\n",
       "      <td>3.557337e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <td>9.095532e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius_worst</th>\n",
       "      <td>-1.729385e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_worst</th>\n",
       "      <td>8.232588e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_worst</th>\n",
       "      <td>-6.543446e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_worst</th>\n",
       "      <td>2.866711e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_worst</th>\n",
       "      <td>-2.489072e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_worst</th>\n",
       "      <td>1.883159e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_worst</th>\n",
       "      <td>2.544239e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points_worst</th>\n",
       "      <td>6.563552e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_worst</th>\n",
       "      <td>4.904635e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <td>4.771560e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 coef\n",
       "constante               -2.373277e-03\n",
       "id                       3.063399e-11\n",
       "radius_mean             -1.651326e-02\n",
       "texture_mean            -3.903975e-04\n",
       "perimeter_mean          -8.076346e-02\n",
       "area_mean               -1.538918e-02\n",
       "smoothness_mean         -6.912733e-05\n",
       "compactness_mean         5.062547e-04\n",
       "concavity_mean           8.992989e-04\n",
       "concave points_mean      3.583258e-04\n",
       "symmetry_mean           -1.470822e-04\n",
       "fractal_dimension_mean  -8.579488e-05\n",
       "radius_se               -1.440265e-04\n",
       "texture_se              -4.259302e-04\n",
       "perimeter_se             1.833983e-03\n",
       "area_se                  2.905569e-02\n",
       "smoothness_se            1.714537e-06\n",
       "compactness_se           1.418742e-04\n",
       "concavity_se             1.896924e-04\n",
       "concave points_se        4.237894e-05\n",
       "symmetry_se              3.557337e-06\n",
       "fractal_dimension_se     9.095532e-06\n",
       "radius_worst            -1.729385e-02\n",
       "texture_worst            8.232588e-03\n",
       "perimeter_worst         -6.543446e-02\n",
       "area_worst               2.866711e-02\n",
       "smoothness_worst        -2.489072e-05\n",
       "compactness_worst        1.883159e-03\n",
       "concavity_worst          2.544239e-03\n",
       "concave points_worst     6.563552e-04\n",
       "symmetry_worst           4.904635e-05\n",
       "fractal_dimension_worst  4.771560e-05"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#comprendre les coefficients du modèle, scikit-learn stocke les informations dans .coef_, nous allons les afficher de manière plus agréable dans un DataFrame avec la constante du modèle :\n",
    "coef = pd.DataFrame(np.concatenate([modele_logit.intercept_.reshape(-1,1),\n",
    "                             modele_logit.coef_],axis=1),\n",
    "             index = [\"coef\"],\n",
    "             columns = [\"constante\"]+list(X.columns)).T\n",
    "\n",
    "coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3ed29361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 456 entries, 265 to 102\n",
      "Data columns (total 32 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   const                    456 non-null    float64\n",
      " 1   id                       456 non-null    int64  \n",
      " 2   radius_mean              456 non-null    float64\n",
      " 3   texture_mean             456 non-null    float64\n",
      " 4   perimeter_mean           456 non-null    float64\n",
      " 5   area_mean                456 non-null    float64\n",
      " 6   smoothness_mean          456 non-null    float64\n",
      " 7   compactness_mean         456 non-null    float64\n",
      " 8   concavity_mean           456 non-null    float64\n",
      " 9   concave points_mean      456 non-null    float64\n",
      " 10  symmetry_mean            456 non-null    float64\n",
      " 11  fractal_dimension_mean   456 non-null    float64\n",
      " 12  radius_se                456 non-null    float64\n",
      " 13  texture_se               456 non-null    float64\n",
      " 14  perimeter_se             456 non-null    float64\n",
      " 15  area_se                  456 non-null    float64\n",
      " 16  smoothness_se            456 non-null    float64\n",
      " 17  compactness_se           456 non-null    float64\n",
      " 18  concavity_se             456 non-null    float64\n",
      " 19  concave points_se        456 non-null    float64\n",
      " 20  symmetry_se              456 non-null    float64\n",
      " 21  fractal_dimension_se     456 non-null    float64\n",
      " 22  radius_worst             456 non-null    float64\n",
      " 23  texture_worst            456 non-null    float64\n",
      " 24  perimeter_worst          456 non-null    float64\n",
      " 25  area_worst               456 non-null    float64\n",
      " 26  smoothness_worst         456 non-null    float64\n",
      " 27  compactness_worst        456 non-null    float64\n",
      " 28  concavity_worst          456 non-null    float64\n",
      " 29  concave points_worst     456 non-null    float64\n",
      " 30  symmetry_worst           456 non-null    float64\n",
      " 31  fractal_dimension_worst  456 non-null    float64\n",
      "dtypes: float64(31), int64(1)\n",
      "memory usage: 117.6 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#importation de l'outil \n",
    "from statsmodels.tools import add_constant \n",
    " \n",
    "#données X avec la constante \n",
    "XTrainBis = sm.tools.add_constant(X_train) \n",
    " \n",
    "#vérifier la structure \n",
    "print(XTrainBis.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0f8c0865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     const        id  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "265    1.0  88995002       20.730         31.12          135.70     1419.0   \n",
      "68     1.0    859471        9.029         17.33           58.79      250.5   \n",
      "181    1.0    873593       21.090         26.57          142.70     1311.0   \n",
      "63     1.0    859196        9.173         13.86           59.20      260.9   \n",
      "248    1.0  88466802       10.650         25.22           68.01      347.0   \n",
      "\n",
      "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "265          0.09469           0.11430         0.13670              0.08646   \n",
      "68           0.10660           0.14130         0.31300              0.04375   \n",
      "181          0.11410           0.28320         0.24870              0.14960   \n",
      "63           0.07721           0.08751         0.05988              0.02180   \n",
      "248          0.09657           0.07234         0.02379              0.01615   \n",
      "\n",
      "     ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
      "265  ...         32.49          47.16           214.00      3432.0   \n",
      "68   ...         10.31          22.65            65.50       324.7   \n",
      "181  ...         26.68          33.48           176.50      2089.0   \n",
      "63   ...         10.01          19.23            65.59       310.1   \n",
      "248  ...         12.25          35.19            77.98       455.7   \n",
      "\n",
      "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
      "265           0.14010             0.2644           0.3442   \n",
      "68            0.14820             0.4365           1.2520   \n",
      "181           0.14910             0.7584           0.6780   \n",
      "63            0.09836             0.1678           0.1397   \n",
      "248           0.14990             0.1398           0.1125   \n",
      "\n",
      "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
      "265               0.16590          0.2868                  0.08218  \n",
      "68                0.17500          0.4228                  0.11750  \n",
      "181               0.29030          0.4098                  0.12840  \n",
      "63                0.05087          0.3282                  0.08490  \n",
      "248               0.06136          0.3409                  0.08147  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "#visualisation des premières lignes de la structure \n",
    "#premières lignes \n",
    "print(XTrainBis.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa80843",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
